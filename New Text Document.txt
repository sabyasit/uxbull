
env.localModelPath = '/assets/models';
env.allowRemoteModels = false;

"@xenova/transformers": "^2.17.2",

import { Component, OnInit } from '@angular/core';
import { pipeline } from '@xenova/transformers';

interface SimilarityResult {
    text: string;
    score: number;
}

@Component({
    selector: 'app-string-similarity',
    templateUrl: './string-similarity.component.html',
    styleUrls: ['./string-similarity.component.css']
})
export class StringSimilarityComponent implements OnInit {
    sourceText: string = 'apple pie\napple juice\ncherry tart\nchocolate cake\nstrawberry ice cream\ncar engine\ntruck tire';
    searchText: string = 'fruit dessert';
    results: SimilarityResult[] = [];
    isLoading: boolean = false;
    statusMessage: string = '';

    extractor: any = null; // Type as any to avoid strict type issues for now, or use Pipeline if types available

    constructor() { }

    async ngOnInit() {
        this.statusMessage = 'Loading model... this may take a while initially.';
        this.isLoading = true;
        try {
            // Load the feature extraction pipeline
            this.extractor = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
            this.statusMessage = 'Model loaded. Ready.';
        } catch (error) {
            console.error('Error loading model:', error);
            this.statusMessage = 'Error loading model. Check console.';
        } finally {
            this.isLoading = false;
        }
    }

    async search() {
        if (!this.extractor) {
            this.statusMessage = 'Model not loaded yet.';
            return;
        }

        if (!this.sourceText.trim() || !this.searchText.trim()) {
            return;
        }

        this.isLoading = true;
        this.statusMessage = 'Computing embeddings...';
        this.results = [];

        try {
            const candidates = this.sourceText.split('\n').filter(line => line.trim() !== '');

            // Get embedding for the search query
            const queryOutput = await this.extractor(this.searchText, { pooling: 'mean', normalize: true });
            const queryEmbedding = queryOutput.data;

            const scoredCandidates: SimilarityResult[] = [];

            // Get embeddings for candidates and calculate cosine similarity
            // Note: For large lists, this should be batched. For this demo, we do one by one or small batch.
            // pipeline handles batching if we pass an array, often faster.
            const candidateOutput = await this.extractor(candidates, { pooling: 'mean', normalize: true });

            // candidateOutput.data is a flattened float32array if multiple inputs
            // Check shape: [batch_size, hidden_size]
            const hiddenSize = queryOutput.dims[1];

            for (let i = 0; i < candidates.length; i++) {
                const candidateEmbedding = candidateOutput[i].data; // Access via index if the output allows, or slice raw data

                // transformers.js output for batch might be a Tensor where .data is the flat array.
                // But pipeline() with array input usually returns an array of Tensors or a batched Tensor?
                // Let's verify behavior. standard behavior for feature-extraction with array is array of Tensors.

                // Actually, let's play safe and check type, or use the Tensor methods.
                // Assuming cosine similarity on normalized vectors is just dot product.

                const score = this.cosineSimilarity(queryEmbedding, candidateEmbedding);
                scoredCandidates.push({ text: candidates[i], score });
            }

            this.results = scoredCandidates.sort((a, b) => b.score - a.score);
            this.statusMessage = 'Done.';

        } catch (error) {
            console.error('Error during search:', error);
            this.statusMessage = 'Error during search.';
        } finally {
            this.isLoading = false;
        }
    }

    cosineSimilarity(a: Float32Array | number[], b: Float32Array | number[]): number {
        let dotProduct = 0;
        for (let i = 0; i < a.length; i++) {
            dotProduct += a[i] * b[i];
        }
        // Since we requested { normalize: true }, the vectors are already unit vectors.
        // So cosine similarity is just the dot product.
        return dotProduct;
    }
}

You are a Resume Validator and Resume Enhancement Assistant.

Your job is to analyze the provided resume text and return a structured validation report.

You MUST check the resume for missing required fields, detect gaps between jobs, and suggest enhancements.

Required fields to validate:

1) Experience Summary (must exist as a dedicated summary section or paragraph)

2) Work Experience entries must include:
   - company name
   - designation/title
   - start date
   - end date (or Present)

3) Skills (must exist as a list or section)

4) Projects entries must include:
   - project name
   - role
   - responsibilities
   - project description
   - start date
   - end date
   - tech stack

5) Education entries must include:
   - institution name
   - field of study
   - passing year

6) Certifications (ONLY if any certification section/entry exists in the resume):
   - certification name
   - issuer name
   - year of completion

Rules:
- If any required field or sub-field is missing, list it under "missing_information".
- For Certifications:
  - If certifications are present but any sub-field is missing, mark those missing sub-fields.
  - If no certifications are mentioned anywhere in the resume, do NOT mark Certifications as missing.

Gaps finding:
- Identify any time gap between the end date of one job and the start date of the next job.
- Consider a "gap" if it is more than 30 days.
- If dates are missing or unclear, mention that gap detection is partially blocked due to missing dates.

Enhancement:
1) Experience Summary:
   - If missing OR too short OR not ATS-friendly, add an enhancement recommendation.
   - If Experience Summary enhancement is required, suggest an ATS-standard professional summary format using:
     - Years of experience (if not provided, use "X+ years" as placeholder)
     - Primary role/title
     - Domain/industry exposure
     - Key technical skills
     - Key achievements (impact-based)
     - Keywords aligned with the candidate’s profile
     Provide a ready-to-use summary template in the enhancements list.

2) Suggest AI trending skills relevant to the resume’s domain/role.
   AI trending skills include (but are not limited to):
   - Generative AI (GenAI), LLMs
   - Prompt Engineering
   - RAG (Retrieval Augmented Generation)
   - Fine-tuning / LoRA
   - AI Agents / Agentic workflows
   - Vector Databases (Pinecone, Weaviate, FAISS, Chroma)
   - LangChain / LlamaIndex
   - OpenAI API / Azure OpenAI
   - ML fundamentals (supervised/unsupervised learning)
   - MLOps basics (model serving, monitoring)
   Only suggest AI skills that fit the resume context.

Output format MUST be valid JSON with exactly these keys:
{
  "missing_information": [],
  "gaps": [],
  "enhancements_required": []
}

Each item should be clear and actionable.
Do NOT include extra keys, explanations, markdown, or text outside JSON.


Validate the following resume and return missing information, gaps, and enhancements required.

Resume Text:
"""
{RESUME_TEXT_HERE}
"""


import os
from io import BytesIO
from pypdf import PdfReader, PdfWriter
from reportlab.pdfgen import canvas
from reportlab.lib.utils import simpleSplit

def create_content_page(page_width, page_height):
    """
    Creates a temporary PDF page with 3 paragraphs and bullet points using ReportLab.
    Matches the dimensions of the existing PDF.
    """
    packet = BytesIO()
    # Create a new PDF with Reportlab
    can = canvas.Canvas(packet, pagesize=(page_width, page_height))
    
    # Margins and dimensions
    margin = 50
    text_width = page_width - 2 * margin
    
    # Starting Y position (from top margin)
    start_y = page_height - 50
    y_position = start_y
    
    # Title
    can.setFont("Helvetica-Bold", 16)
    can.drawString(margin, y_position, "Added Page with Bullet Points")
    y_position -= 30
    
    paragraphs = [
        {
            "title": "1. Introduction to New Features",
            "text": "This section introduces the new capabilities added to the system. The integration allows for seamless processing of documents even when the text is very long and needs to wrap to the next line to ensure readability and proper layout on the PDF page.",
            "points": ["Enhanced performance across all modules", "Better reliability with improved error handling mechanisms", "Scalable architecture designed for future growth and high load scenarios Scalable architecture designed for future growth and high load scenarios Scalable architecture designed for future growth and high load scenarios"]
        },
        {
            "title": "2. Implementation Details",
            "text": "The implementation focuses on modularity and ease of maintenance. Developers can easily extend the functionality by adding new modules or plugins without affecting the core system. This ensures a robust and flexible codebase.",
            "points": ["Python-based solution utilizing modern libraries", "Uses pypdf library for robust PDF manipulation and merging capabilities", "ReportLab for dynamic PDF generation and advanced text formatting features"]
        },
        {
            "title": "3. Future Roadmap",
            "text": "We plan to add more features in the upcoming release cycles to support a wider range of document formats including proprietary and open standards. The goal is to provide a comprehensive document processing solution.",
            "points": ["Support for DOCX and other office formats", "Cloud integration with major providers like AWS, Azure, and GCP", "Real-time collaboration features allowing multiple users to edit documents simultaneously"]
        }
    ]
    
    for para in paragraphs:
        # Title of the paragraph
        can.setFont("Helvetica-Bold", 12)
        can.drawString(margin, y_position, para["title"])
        y_position -= 20
        
        # Paragraph text
        can.setFont("Helvetica", 11)
        # Use simpleSplit to wrap text that fits within the text_width
        text_lines = simpleSplit(para["text"], "Helvetica", 11, text_width)
        
        for line in text_lines:
            can.drawString(margin, y_position, line)
            y_position -= 15
            
        y_position -= 5 # Small gap before bullets
        
        # Bullet points
        for point in para["points"]:
            # Draw bullet
            can.drawString(margin + 20, y_position, "•")
            
            # Calculate available width for bullet text (margin + bullet indent + text indent)
            bullet_text_width = text_width - 35 
            point_lines = simpleSplit(point, "Helvetica", 11, bullet_text_width)
            
            for line in point_lines:
                can.drawString(margin + 35, y_position, line)
                y_position -= 15
            
        y_position -= 20  # Extra space between sections
        
        # Simple check for page break
        if y_position < 50:
            can.showPage()
            y_position = start_y
            can.setFont("Helvetica", 11)
        
    can.save()
    packet.seek(0)
    return packet

def add_page_with_bullets(input_file_path: str, output_file_path: str = None):
    """
    Adds a new page with 3 paragraphs and bullet points to an existing PDF.
    
    Args:
        input_file_path (str): Path to the source PDF.
        output_file_path (str, optional): Path to save the result. If None, overwrites input.
    """
    if output_file_path is None:
        output_file_path = input_file_path
        
    try:
        # Read the existing PDF
        reader = PdfReader(input_file_path)
        writer = PdfWriter()
        
        # Get dimensions from the first page (assuming uniform size or just extracting from first)
        if len(reader.pages) > 0:
            first_page = reader.pages[0]
            # pypdf pages have mediabox which is usually [0, 0, width, height]
            page_width = float(first_page.mediabox.width)
            page_height = float(first_page.mediabox.height)
        else:
            # Fallback if PDF is empty (unlikely but safe)
            page_width, page_height = 612.0, 792.0 # Standard Letter size
            
        # Copy existing pages
        for page in reader.pages:
            writer.add_page(page)
            
        # Create and add the new page with dynamic dimensions
        new_page_packet = create_content_page(page_width, page_height)
        new_page_reader = PdfReader(new_page_packet)
        # If create_content_page creates multiple pages (due to showPage), add all of them
        for page in new_page_reader.pages:
            writer.add_page(page)
        
        # Write the output
        with open(output_file_path, "wb") as f_out:
            writer.write(f_out)
            
        print(f"Successfully added a new page to: {output_file_path} (Size: {page_width}x{page_height})")
        
    except Exception as e:
        print(f"An error occurred: {e}")

if __name__ == "__main__":
    # Example usage
    current_dir = os.path.dirname(os.path.abspath(__file__))
    input_pdf = os.path.join(current_dir, "1.pdf")
    
    # We output to a new file to preserve the original for repeated testing, 
    # but the function supports overwriting.
    output_pdf = os.path.join(current_dir, "1_updated.pdf")
    
    if os.path.exists(input_pdf):
        add_page_with_bullets(input_pdf, output_pdf)
    else:
        print(f"File not found: {input_pdf}")
