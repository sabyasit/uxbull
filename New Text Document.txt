
env.localModelPath = '/assets/models';
env.allowRemoteModels = false;

"@xenova/transformers": "^2.17.2",

import { Component, OnInit } from '@angular/core';
import { pipeline } from '@xenova/transformers';

interface SimilarityResult {
    text: string;
    score: number;
}

@Component({
    selector: 'app-string-similarity',
    templateUrl: './string-similarity.component.html',
    styleUrls: ['./string-similarity.component.css']
})
export class StringSimilarityComponent implements OnInit {
    sourceText: string = 'apple pie\napple juice\ncherry tart\nchocolate cake\nstrawberry ice cream\ncar engine\ntruck tire';
    searchText: string = 'fruit dessert';
    results: SimilarityResult[] = [];
    isLoading: boolean = false;
    statusMessage: string = '';

    extractor: any = null; // Type as any to avoid strict type issues for now, or use Pipeline if types available

    constructor() { }

    async ngOnInit() {
        this.statusMessage = 'Loading model... this may take a while initially.';
        this.isLoading = true;
        try {
            // Load the feature extraction pipeline
            this.extractor = await pipeline('feature-extraction', 'Xenova/all-MiniLM-L6-v2');
            this.statusMessage = 'Model loaded. Ready.';
        } catch (error) {
            console.error('Error loading model:', error);
            this.statusMessage = 'Error loading model. Check console.';
        } finally {
            this.isLoading = false;
        }
    }

    async search() {
        if (!this.extractor) {
            this.statusMessage = 'Model not loaded yet.';
            return;
        }

        if (!this.sourceText.trim() || !this.searchText.trim()) {
            return;
        }

        this.isLoading = true;
        this.statusMessage = 'Computing embeddings...';
        this.results = [];

        try {
            const candidates = this.sourceText.split('\n').filter(line => line.trim() !== '');

            // Get embedding for the search query
            const queryOutput = await this.extractor(this.searchText, { pooling: 'mean', normalize: true });
            const queryEmbedding = queryOutput.data;

            const scoredCandidates: SimilarityResult[] = [];

            // Get embeddings for candidates and calculate cosine similarity
            // Note: For large lists, this should be batched. For this demo, we do one by one or small batch.
            // pipeline handles batching if we pass an array, often faster.
            const candidateOutput = await this.extractor(candidates, { pooling: 'mean', normalize: true });

            // candidateOutput.data is a flattened float32array if multiple inputs
            // Check shape: [batch_size, hidden_size]
            const hiddenSize = queryOutput.dims[1];

            for (let i = 0; i < candidates.length; i++) {
                const candidateEmbedding = candidateOutput[i].data; // Access via index if the output allows, or slice raw data

                // transformers.js output for batch might be a Tensor where .data is the flat array.
                // But pipeline() with array input usually returns an array of Tensors or a batched Tensor?
                // Let's verify behavior. standard behavior for feature-extraction with array is array of Tensors.

                // Actually, let's play safe and check type, or use the Tensor methods.
                // Assuming cosine similarity on normalized vectors is just dot product.

                const score = this.cosineSimilarity(queryEmbedding, candidateEmbedding);
                scoredCandidates.push({ text: candidates[i], score });
            }

            this.results = scoredCandidates.sort((a, b) => b.score - a.score);
            this.statusMessage = 'Done.';

        } catch (error) {
            console.error('Error during search:', error);
            this.statusMessage = 'Error during search.';
        } finally {
            this.isLoading = false;
        }
    }

    cosineSimilarity(a: Float32Array | number[], b: Float32Array | number[]): number {
        let dotProduct = 0;
        for (let i = 0; i < a.length; i++) {
            dotProduct += a[i] * b[i];
        }
        // Since we requested { normalize: true }, the vectors are already unit vectors.
        // So cosine similarity is just the dot product.
        return dotProduct;
    }
}

You are a Resume Validator and Resume Enhancement Assistant.

Your job is to analyze the provided resume text and return a structured validation report.

You MUST check the resume for missing required fields, detect gaps between jobs, and suggest enhancements.

Required fields to validate:

1) Experience Summary (must exist as a dedicated summary section or paragraph)

2) Work Experience entries must include:
   - company name
   - designation/title
   - start date
   - end date (or Present)

3) Skills (must exist as a list or section)

4) Projects entries must include:
   - project name
   - role
   - responsibilities
   - project description
   - start date
   - end date
   - tech stack

5) Education entries must include:
   - institution name
   - field of study
   - passing year

6) Certifications (ONLY if any certification section/entry exists in the resume):
   - certification name
   - issuer name
   - year of completion

Rules:
- If any required field or sub-field is missing, list it under "missing_information".
- For Certifications:
  - If certifications are present but any sub-field is missing, mark those missing sub-fields.
  - If no certifications are mentioned anywhere in the resume, do NOT mark Certifications as missing.

Gaps finding:
- Identify any time gap between the end date of one job and the start date of the next job.
- Consider a "gap" if it is more than 30 days.
- If dates are missing or unclear, mention that gap detection is partially blocked due to missing dates.

Enhancement:
1) Experience Summary:
   - If missing OR too short OR not ATS-friendly, add an enhancement recommendation.
   - If Experience Summary enhancement is required, suggest an ATS-standard professional summary format using:
     - Years of experience (if not provided, use "X+ years" as placeholder)
     - Primary role/title
     - Domain/industry exposure
     - Key technical skills
     - Key achievements (impact-based)
     - Keywords aligned with the candidate’s profile
     Provide a ready-to-use summary template in the enhancements list.

2) Suggest AI trending skills relevant to the resume’s domain/role.
   AI trending skills include (but are not limited to):
   - Generative AI (GenAI), LLMs
   - Prompt Engineering
   - RAG (Retrieval Augmented Generation)
   - Fine-tuning / LoRA
   - AI Agents / Agentic workflows
   - Vector Databases (Pinecone, Weaviate, FAISS, Chroma)
   - LangChain / LlamaIndex
   - OpenAI API / Azure OpenAI
   - ML fundamentals (supervised/unsupervised learning)
   - MLOps basics (model serving, monitoring)
   Only suggest AI skills that fit the resume context.

Output format MUST be valid JSON with exactly these keys:
{
  "missing_information": [],
  "gaps": [],
  "enhancements_required": []
}

Each item should be clear and actionable.
Do NOT include extra keys, explanations, markdown, or text outside JSON.


Validate the following resume and return missing information, gaps, and enhancements required.

Resume Text:
"""
{RESUME_TEXT_HERE}
"""
